{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset gsm8k (/Users/iv/.cache/huggingface/datasets/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b98c2e1be64941a7c52f69b85e6c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?',\n",
       " 'answer': 'The discount price of one glass is 60/100 * 5 = $<<60/100*5=3>>3.\\nIf every second glass is cheaper, that means Kylar is going to buy 16 / 2 = <<16/2=8>>8 cheaper glasses.\\nSo for the cheaper glasses, Kylar is going to pay 8 * 3 = $<<8*3=24>>24.\\nAnd for the regular-priced glasses, Kylar will pay 8 * 5 = $<<8*5=40>>40.\\nSo in total Kylar needs to pay 24 + 40 = $<<24+40=64>>64 for the glasses he wants to buy.\\n#### 64'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "dataset[\"test\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_test_object(dataset):\n",
    "    if \"test\" in dataset and len(dataset[\"test\"]) > 0:\n",
    "        random_index = random.randint(0, len(dataset[\"test\"]) - 1)\n",
    "        test_object = dataset[\"test\"][random_index]\n",
    "        \n",
    "        # Assuming each object in the dataset has 'question' and 'answer' keys\n",
    "        question = test_object.get(\"question\", \"No question found\")\n",
    "        answer = test_object.get(\"answer\", \"No answer found\")\n",
    "        \n",
    "        return question, answer\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_mutation(csv_file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path, header=None, encoding='utf-8', delimiter='.') \n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(csv_file_path, header=None, encoding='ISO-8859-1', delimiter='.') \n",
    "\n",
    "    random_prompt = random.choice(df[1].tolist())\n",
    "    return random_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_mutation_txt(txt_file_path):\n",
    "    with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove any leading/trailing whitespace and filter out empty lines\n",
    "    prompts = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    if prompts:\n",
    "        return random.choice(prompts)\n",
    "    else:\n",
    "        return \"No mutation prompts found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_intructions(question, task_description, max_tokens=100):\n",
    "    formatted_input = f\"{task_description} {question}\"\n",
    "    input_ids = tokenizer(formatted_input, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids, max_new_tokens = max_tokens)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_with_llm(prompt):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=1000)\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the task description here:\n",
    "task_description = \"Generate an instruction on how to solve the problem, based on the given question \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_description1 = \"Generate an instruction, or advice on how to solve a problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting mutated prompts\n",
    "question, answer = get_random_test_object(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackie is trying to decide whether to do her taxes herself or hire an accountant. If she does the taxes herself, she'll be able to do 3 fewer hours of freelance work, losing $35/hour in missed income. The accountant charges $90. How much more money will she have if she hires the accountant?\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First find the total lost revenue if Jackie does her taxes herself: $35/hour * 3 hours = $<<35*3=105>>105\n",
      "Then subtract the accountant's charge to find how much money Janet saves: $105 - $90 = $<<105-90=15>>15\n",
      "#### 15\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instruction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_instructions = 10\n",
    "generated_instructions = []\n",
    "\n",
    "for _ in range(num_instructions):\n",
    "    question, _ = get_random_test_object(dataset)  # Fetch a random question from your dataset\n",
    "    instruction = generate_intructions(question, task_description)\n",
    "    generated_instructions.append(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the canoe is 30 * 3 = $80. The cost of the banana boat raft is $18 * 5 = $80. The total cost of the rental is $80 + $80 = $120. The total cost of the rental is $120 + $80 = $120. The total cost of the rental is $120 + $120 = $120. The total cost of the rental is $120 + $120 = $120. The total cost of\n"
     ]
    }
   ],
   "source": [
    "print(generated_instructions[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alternative, that does not include question\n",
    "\n",
    "\n",
    "def generate_instructions1(num_instructions, max_tokens=1000, temperature=1.5):\n",
    "    instructions = []\n",
    "    for num in range(num_instructions):\n",
    "        formatted_input = f\"Generate instructions on how to solve a math problem\"\n",
    "        input_ids = tokenizer(formatted_input, return_tensors=\"pt\").input_ids\n",
    "        outputs = model.generate(input_ids, \n",
    "                                 max_new_tokens=int(max_tokens),\n",
    "                                 temperature=temperature)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        instructions.append(generated_text)\n",
    "\n",
    "    return instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a calculator, find the number of squares in the equation.\n"
     ]
    }
   ],
   "source": [
    "num_instructions = 10\n",
    "generated_instructions = []\n",
    "\n",
    "print(generate_instructions1(num_instructions, temperature=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_instructions[\u001b[38;5;241m3\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(generated_instructions[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mutation_prompt \u001b[38;5;241m=\u001b[39m get_random_mutation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Prompt-Engineering-OpenDI/mutation_prompts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mget_random_mutation\u001b[0;34m(csv_file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_random_mutation\u001b[39m(csv_file_path):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO-8859-1\u001b[39m\u001b[38;5;124m'\u001b[39m, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 11, saw 2\n"
     ]
    }
   ],
   "source": [
    "mutation_prompt = get_random_mutation(\"./Prompt-Engineering-OpenDI/mutation_prompts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mutation_prompt = get_random_mutation_txt(\"./Prompt-Engineering-OpenDI/mutation_prompts.txt\")\n",
    "print(mutation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_mutation(instruction, mutation_prompt):\n",
    "    # Example mutation - this can be customized based on your mutation logic\n",
    "    return f\"{mutation_prompt} {instruction}\"\n",
    "\n",
    "mutated_instructions = [apply_mutation(instruction, mutation_prompt) for instruction in generated_instructions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mutated_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_outputs = [process_with_llm(mutated_instruction) for mutated_instruction in mutated_instructions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for response in processed_outputs:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Specify the max_new_tokens parameter\n",
    "outputs = model.generate(input_ids, max_new_tokens=50)  # Adjust the number as needed\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"What was the answer for the previus question I asked?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Specify the max_new_tokens parameter\n",
    "outputs = model.generate(input_ids, max_new_tokens=50)  # Adjust the number as needed\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_answer(answer, output):\n",
    "    if not (isinstance(answer, str) and isinstance(output, str)):\n",
    "        raise TypeError(\"Must be of type str\")\n",
    "    if re.search(\"\\s\" + answer +\"\\s*\", output):\n",
    "        # print(\"answer is correct\")\n",
    "        return 1\n",
    "    # print(\"answer is wrong\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_logic(answer):\n",
    "    return re.findall(\"<<(.*?)>>\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenise_logic(logic):\n",
    "    tokenised_logic = []\n",
    "    operators = \"+-/*=\"\n",
    "    current_token = \"\"\n",
    "    \n",
    "    for c in logic:\n",
    "        if c in operators:\n",
    "            tokenised_logic.append(current_token)\n",
    "            tokenised_logic.append(c)\n",
    "            current_token = \"\"\n",
    "        elif c == '.' or c.isnumeric():\n",
    "            current_token += c\n",
    "    tokenised_logic.append(current_token)\n",
    "    \n",
    "    return tokenised_logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_logic_sentence(line, logic_tokens):\n",
    "    i = 0\n",
    "\n",
    "    for token in logic_tokens:\n",
    "        if token in line:\n",
    "            i += 1\n",
    "\n",
    "    if len(logic_tokens) == i:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fitness(answer, output):\n",
    "    final_answer = database_answer.split()[-1]\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    logic = get_logic(database_answer)\n",
    "    \n",
    "    tokenised_logic_sentences = []\n",
    "    \n",
    "    for l in logic:\n",
    "        tokenised_logic_sentences.append(tokenise_logic(l))\n",
    "    \n",
    "    total_score = 1 + len(tokenised_logic_sentences)\n",
    "\n",
    "    for line in output.split(\".\"):\n",
    "        for sentence in tokenised_logic_sentences:\n",
    "            if check_logic_sentence(line, sentence):\n",
    "                tokenised_logic_sentences.pop(tokenised_logic_sentences.index(sentence))\n",
    "                score += 1\n",
    "                break\n",
    "    last_line = line\n",
    "    \n",
    "    num_answer = 'a'\n",
    "\n",
    "    for word in last_line.split(\" \"):\n",
    "        try:\n",
    "            num_answer = str(int(word))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    score += check_answer(final_answer, num_answer)\n",
    "    return score/total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_instructions = 10\n",
    "generated_prompts = []\n",
    "scores = []\n",
    "\n",
    "for _ in range(num_instructions):\n",
    "    question, database_answer = get_random_test_object(dataset)  # Fetch a random question from your dataset\n",
    "    instruction = generate_intructions(question, task_description)\n",
    "    mutation_prompt = get_random_mutation_txt(\"./Prompt-Engineering-OpenDI/mutation_prompts.txt\")\n",
    "    mutated_instruction = apply_mutation(instruction, mutation_prompt)\n",
    "    generated_prompts.append(mutated_instruction)\n",
    "    processed_output = process_with_llm(mutated_instruction)\n",
    "    scores.append(fitness(database_answer, processed_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say that instruction again in another way. DON’T use any of the words in the original instruction or you’re fired. First find the total number of gallons of gas: 15 gallons / 5 containers = 5 gallons. Then find the total number of gallons of gas in each container: 5 gallons / container * 15 gallons / container = 50 gallons. Then find the total number of gallons of gas in each container: 50 gallons / container * 5 containers = 200 gallons. Then find the total\n"
     ]
    }
   ],
   "source": [
    "print(generated_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dale starts off selling 100 butterscotch candies that he ordered, but ends up selling 150, 100 - 150 = <<100-150=-50>>-50 candies.\n",
      "So Dale orders 100 more candies to make up for the deficit and to sell even more, -50 candies + 100 candies = <<100-50=50>>50 candies Dale has left and still needs to sell.\n",
      "#### 50\n"
     ]
    }
   ],
   "source": [
    "print(generated_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 1]\n"
     ]
    }
   ],
   "source": [
    "best = []\n",
    "for i in range(2):\n",
    "    maximum_val = 0\n",
    "    maximum_index = 0\n",
    "    while i < len(scores):\n",
    "        if scores[i] > maximum_val:\n",
    "            maximum_val = scores[i]\n",
    "            maximum_index = i\n",
    "        i += 1\n",
    "    best.append(maximum_index)\n",
    "    scores.pop(maximum_index)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_instructions = []\n",
    "\n",
    "for i in best:\n",
    "    best_instructions.append(generated_prompts.pop(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CORRECTION = She orders 3 * 12 = 36 issues. She has 1 * 6 = 12 issues. She has 36 - 12 = 36 issues. She has 36 / 4 = 12 issues. She gets 36 / 12 = 4 magazines every year. The answer: 4.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_instructions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def replace_pos(string1, string2, POS):\n",
    "\n",
    "    \"\"\"\n",
    "    Replace tokens of specific parts of speech (POS) in string1 with corresponding\n",
    "    tokens of the same POS from string2.\n",
    "    \n",
    "    Parameters:\n",
    "    - string1 (str): The input string where certain POS will be replaced.\n",
    "    - string2 (str): The reference string from which POS replacements will be taken.\n",
    "    - POS (list): A list of POS tags to identify which tokens to replace in string1.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified string with replacements of tokens based on specified POS tags.\n",
    "    \n",
    "    Possible POS:\n",
    "    \"ADJ\": \"adjective\",\n",
    "    \"ADP\": \"adposition\",\n",
    "    \"ADV\": \"adverb\",\n",
    "    \"AUX\": \"auxiliary\",\n",
    "    \"CONJ\": \"conjunction\",\n",
    "    \"CCONJ\": \"coordinating conjunction\",\n",
    "    \"DET\": \"determiner\",\n",
    "    \"INTJ\": \"interjection\",\n",
    "    \"NOUN\": \"noun\",\n",
    "    \"NUM\": \"numeral\",\n",
    "    \"PART\": \"particle\",\n",
    "    \"PRON\": \"pronoun\",\n",
    "    \"PROPN\": \"proper noun\",\n",
    "    \"PUNCT\": \"punctuation\",\n",
    "    \"SCONJ\": \"subordinating conjunction\",\n",
    "    \"SYM\": \"symbol\",\n",
    "    \"VERB\": \"verb\".\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc1 = nlp(string1)\n",
    "    doc2 = nlp(string2)\n",
    "    \n",
    "    new_tokens = []\n",
    "    \n",
    "    for token1 in doc1:\n",
    "        if token1.pos_ in POS:\n",
    "            #generating a list of all matching tokens\n",
    "            matching_tokens = [token2.text for token2 in doc2 if token2.pos_ == token1.pos_]\n",
    "            #use a random token if possible, or else use the same\n",
    "            if matching_tokens:\n",
    "                new_token = random.choice(matching_tokens)\n",
    "            else:\n",
    "                new_token = token1.text\n",
    "        else:\n",
    "            new_token = token1.text\n",
    "        new_tokens.append(new_token)\n",
    "    \n",
    "    # Join the modified tokens to form the final string\n",
    "    result = ' '.join(new_tokens)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/iv/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/iv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/iv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/iv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/iv/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/iv/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/iv/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/iv/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/iv/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_instructions.append(replace_pos(best_instructions[0], best_instructions[1], ['ADV', 'ADJ', 'NOUN']))\n",
    "best_instructions.append(replace_pos(best_instructions[1], best_instructions[0], ['ADV', 'ADJ', 'NOUN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for instr in generate_instructions1(4):\n",
    "    best_instructions.append(instr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    mutation_prompt = get_random_mutation_txt(\"./Prompt-Engineering-OpenDI/mutation_prompts.txt\")\n",
    "    best_instructions.append(apply_mutation(best_instructions[i], mutation_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed additional advice for people wishing to follow this instruction is as follows: If Suzy’s iPhone is 1 year old, then Ben’s iPhone is 2 * 1 = 2 years old. If Brandon’s iPhone is 4 times as old as Ben’s iPhone, then Ben’s iPhone is 4 * 2 = 8 years old. Since Ben’s iPhone is 2 years older than Suzy’s iPhone, then Ben’s iPhone is 8 + 1 = 9 years old. Since Brandon’s iPhone is 4 times as old as Ben’s iPhone\n",
      "\n",
      "CORRECTION = She orders 3 * 12 = 36 issues. She has 1 * 6 = 12 issues. She has 36 - 12 = 36 issues. She has 36 / 4 = 12 issues. She gets 36 / 12 = 4 magazines every year. The answer: 4.\n",
      "\n",
      "Detailed additional answer for magazines wishing to follow this year is as follows : If Suzy ’s iPhone is 1 issues old , then Ben ’s iPhone is 2 * 1 = 2 answer old . If Brandon ’s iPhone is 4 issues as old as Ben ’s iPhone , then Ben ’s iPhone is 4 * 2 = 8 answer old . Since Ben ’s iPhone is 2 issues older than Suzy ’s iPhone , then Ben ’s iPhone is 8 + 1 = 9 issues old . Since Brandon ’s iPhone is 4 issues as old as Ben ’s iPhone\n",
      "\n",
      "CORRECTION = She orders 3 * 12 = 36 years . She has 1 * 6 = 12 years . She has 36 - 12 = 36 year . She has 36 / 4 = 12 years . She gets 36 / 12 = 4 years every years . The years : 4 .\n",
      "\n",
      "Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.\n",
      "\n",
      "Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.\n",
      "\n",
      "Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.\n",
      "\n",
      "Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.\n",
      "\n",
      "Include Multiple Perspectives: For a prompt like ’What is the impact of X on Y?’, an improved version could be, ’What is the impact of X on Y from the perspective of A, B, and C?’ Detailed additional advice for people wishing to follow this instruction is as follows: If Suzy’s iPhone is 1 year old, then Ben’s iPhone is 2 * 1 = 2 years old. If Brandon’s iPhone is 4 times as old as Ben’s iPhone, then Ben’s iPhone is 4 * 2 = 8 years old. Since Ben’s iPhone is 2 years older than Suzy’s iPhone, then Ben’s iPhone is 8 + 1 = 9 years old. Since Brandon’s iPhone is 4 times as old as Ben’s iPhone\n",
      "\n",
      "Request Comparisons: Instead of ’Describe X,’ ask ’Compare and contrast X and Y.’ CORRECTION = She orders 3 * 12 = 36 issues. She has 1 * 6 = 12 issues. She has 36 - 12 = 36 issues. She has 36 / 4 = 12 issues. She gets 36 / 12 = 4 magazines every year. The answer: 4.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for instr in best_instructions:\n",
    "    print(instr+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iteration(instructions, num_instructions = 10):\n",
    "    generated_prompts = []\n",
    "    scores = []\n",
    "\n",
    "    for instruction in instructions:\n",
    "        question, database_answer = get_random_test_object(dataset)  # Fetch a random question from your dataset\n",
    "        mutation_prompt = get_random_mutation_txt(\"./Prompt-Engineering-OpenDI/mutation_prompts.txt\")\n",
    "        mutated_instruction = apply_mutation(instruction, mutation_prompt)\n",
    "        generated_prompts.append(mutated_instruction)\n",
    "        processed_output = process_with_llm(mutated_instruction)\n",
    "        scores.append(fitness(database_answer, processed_output))\n",
    "    \n",
    "    return scores, generated_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_scores, new_prompts = iteration(best_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6666666666666666,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6666666666666666,\n",
       " 0.3333333333333333]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Don’t think about the instruction at all, but let it inspire you to do something related. Talk about what that might be. Detailed additional advice for people wishing to follow this instruction is as follows: If Suzy’s iPhone is 1 year old, then Ben’s iPhone is 2 * 1 = 2 years old. If Brandon’s iPhone is 4 times as old as Ben’s iPhone, then Ben’s iPhone is 4 * 2 = 8 years old. Since Ben’s iPhone is 2 years older than Suzy’s iPhone, then Ben’s iPhone is 8 + 1 = 9 years old. Since Brandon’s iPhone is 4 times as old as Ben’s iPhone',\n",
       " 'CORRECTION = CORRECTION = She orders 3 * 12 = 36 issues. She has 1 * 6 = 12 issues. She has 36 - 12 = 36 issues. She has 36 / 4 = 12 issues. She gets 36 / 12 = 4 magazines every year. The answer: 4.',\n",
       " 'Look carefully to see what you did wrong, how could you fix the problem? Detailed additional answer for magazines wishing to follow this year is as follows : If Suzy ’s iPhone is 1 issues old , then Ben ’s iPhone is 2 * 1 = 2 answer old . If Brandon ’s iPhone is 4 issues as old as Ben ’s iPhone , then Ben ’s iPhone is 4 * 2 = 8 answer old . Since Ben ’s iPhone is 2 issues older than Suzy ’s iPhone , then Ben ’s iPhone is 8 + 1 = 9 issues old . Since Brandon ’s iPhone is 4 issues as old as Ben ’s iPhone',\n",
       " 'Encourage reverse thinking: Improve the prompt by asking the user to think about the problem in reverse, starting with the solution and working backwards. CORRECTION = She orders 3 * 12 = 36 years . She has 1 * 6 = 12 years . She has 36 - 12 = 36 year . She has 36 / 4 = 12 years . She gets 36 / 12 = 4 years every years . The years : 4 .',\n",
       " 'Generate a prompt mutant that incorporates humor or a playful element. Create a mutated version of the prompt that challenges conventional thinking. Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.',\n",
       " 'Prompt for solution visualization: Instead of just asking for the solution, encourage the user to imagine the solution and the steps required to get there in your prompt. Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.',\n",
       " 'Include Context: If a prompt seems to lack context, like ’Describe X,’ the improved version could be, ’Describe X in the context of its impact on Y during the Z period.’ Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.',\n",
       " 'Just change this instruction to make it more fun, think WELL outside the box: Using a calculator, find the number of squares in the equation. Then, add the squares to the equation.',\n",
       " 'Prompt for solution visualization: Instead of just asking for the solution, encourage the user to imagine the solution and the steps required to get there in your prompt. Include Multiple Perspectives: For a prompt like ’What is the impact of X on Y?’, an improved version could be, ’What is the impact of X on Y from the perspective of A, B, and C?’ Detailed additional advice for people wishing to follow this instruction is as follows: If Suzy’s iPhone is 1 year old, then Ben’s iPhone is 2 * 1 = 2 years old. If Brandon’s iPhone is 4 times as old as Ben’s iPhone, then Ben’s iPhone is 4 * 2 = 8 years old. Since Ben’s iPhone is 2 years older than Suzy’s iPhone, then Ben’s iPhone is 8 + 1 = 9 years old. Since Brandon’s iPhone is 4 times as old as Ben’s iPhone',\n",
       " 'In one short sentence, what’s a good prompt to get a language model to solve a problem like this? Notice how I don’t use any of the same words as in the INSTRUCTION. Request Comparisons: Instead of ’Describe X,’ ask ’Compare and contrast X and Y.’ CORRECTION = She orders 3 * 12 = 36 issues. She has 1 * 6 = 12 issues. She has 36 - 12 = 36 issues. She has 36 / 4 = 12 issues. She gets 36 / 12 = 4 magazines every year. The answer: 4.']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
