{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset gsm8k (/Users/iv/.cache/huggingface/datasets/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5797dec690f4ba1b4f6f43c0c0e9ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?',\n",
       " 'answer': 'The discount price of one glass is 60/100 * 5 = $<<60/100*5=3>>3.\\nIf every second glass is cheaper, that means Kylar is going to buy 16 / 2 = <<16/2=8>>8 cheaper glasses.\\nSo for the cheaper glasses, Kylar is going to pay 8 * 3 = $<<8*3=24>>24.\\nAnd for the regular-priced glasses, Kylar will pay 8 * 5 = $<<8*5=40>>40.\\nSo in total Kylar needs to pay 24 + 40 = $<<24+40=64>>64 for the glasses he wants to buy.\\n#### 64'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "dataset[\"test\"][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_test_object(dataset):\n",
    "    if \"test\" in dataset and len(dataset[\"test\"]) > 0:\n",
    "        random_index = random.randint(0, len(dataset[\"test\"]) - 1)\n",
    "        test_object = dataset[\"test\"][random_index]\n",
    "        \n",
    "        # Assuming each object in the dataset has 'question' and 'answer' keys\n",
    "        question = test_object.get(\"question\", \"No question found\")\n",
    "        answer = test_object.get(\"answer\", \"No answer found\")\n",
    "        \n",
    "        return question, answer\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_mutation(csv_file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path, header=None, encoding='utf-8', delimiter='.') \n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(csv_file_path, header=None, encoding='ISO-8859-1', delimiter='.') \n",
    "\n",
    "    random_prompt = random.choice(df[1].tolist())\n",
    "    return random_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_mutation_txt(txt_file_path):\n",
    "    with open(txt_file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove any leading/trailing whitespace and filter out empty lines\n",
    "    prompts = [line.strip() for line in lines if line.strip()]\n",
    "    \n",
    "    if prompts:\n",
    "        return random.choice(prompts)\n",
    "    else:\n",
    "        return \"No mutation prompts found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write the task description here:\n",
    "task_description = \"Generate an instruction on how to solve the problem, based on the given question \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_description1 = \"Generate an instruction, or advice on how to solve a problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting mutated prompts\n",
    "question, answer = get_random_test_object(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackie is trying to decide whether to do her taxes herself or hire an accountant. If she does the taxes herself, she'll be able to do 3 fewer hours of freelance work, losing $35/hour in missed income. The accountant charges $90. How much more money will she have if she hires the accountant?\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First find the total lost revenue if Jackie does her taxes herself: $35/hour * 3 hours = $<<35*3=105>>105\n",
      "Then subtract the accountant's charge to find how much money Janet saves: $105 - $90 = $<<105-90=15>>15\n",
      "#### 15\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Instruction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_answer(answer, output):\n",
    "    if not (isinstance(answer, str) and isinstance(output, str)):\n",
    "        raise TypeError(\"Must be of type str\")\n",
    "    if re.search(\"\\s\" + answer +\"\\s*\", output):\n",
    "        # print(\"answer is correct\")\n",
    "        return 1\n",
    "    # print(\"answer is wrong\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_logic(answer):\n",
    "    return re.findall(\"<<(.*?)>>\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenise_logic(logic):\n",
    "    tokenised_logic = []\n",
    "    operators = \"+-/*=\"\n",
    "    current_token = \"\"\n",
    "    \n",
    "    for c in logic:\n",
    "        if c in operators:\n",
    "            tokenised_logic.append(current_token)\n",
    "            tokenised_logic.append(c)\n",
    "            current_token = \"\"\n",
    "        elif c == '.' or c.isnumeric():\n",
    "            current_token += c\n",
    "    tokenised_logic.append(current_token)\n",
    "    \n",
    "    return tokenised_logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_logic_sentence(line, logic_tokens):\n",
    "    i = 0\n",
    "\n",
    "    for token in logic_tokens:\n",
    "        if token in line:\n",
    "            i += 1\n",
    "\n",
    "    if len(logic_tokens) == i:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "class llamathwiz:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "        self.gen = 0\n",
    "        \n",
    "    def generate_intructions(self, question, task_description, max_tokens=100):\n",
    "        formatted_input = f\"{task_description} {question}\"\n",
    "        input_ids = tokenizer(formatted_input, return_tensors=\"pt\").input_ids\n",
    "        outputs = model.generate(input_ids, max_new_tokens = max_tokens)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        return generated_text\n",
    "    \n",
    "    def generate_instructions1(self, num_instructions, max_tokens=1000, temperature=1.5):\n",
    "        instructions = []\n",
    "        for num in range(num_instructions):\n",
    "            formatted_input = \"Generate instructions on how to solve a math problem\"\n",
    "            input_ids = tokenizer(formatted_input, return_tensors=\"pt\").input_ids\n",
    "            outputs = model.generate(input_ids, \n",
    "                                     max_new_tokens=int(max_tokens),\n",
    "                                     temperature=temperature)\n",
    "            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            instructions.append(generated_text)\n",
    "\n",
    "        return instructions\n",
    "\n",
    "    def process_with_llm(self, prompt):\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "        output = model.generate(input_ids, max_length=1000)\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        return response\n",
    "    \n",
    "    def apply_mutation(self, instruction, mutation_prompt):\n",
    "        # Example mutation - this can be customized based on your mutation logic\n",
    "        return f\"{mutation_prompt} {instruction}\"\n",
    "    \n",
    "    def fitness(self, database_answer, output):\n",
    "        final_answer = database_answer.split()[-1]\n",
    "\n",
    "        score = 0\n",
    "\n",
    "        logic = get_logic(database_answer)\n",
    "\n",
    "        tokenised_logic_sentences = []\n",
    "\n",
    "        for l in logic:\n",
    "            tokenised_logic_sentences.append(tokenise_logic(l))\n",
    "\n",
    "        total_score = 1 + len(tokenised_logic_sentences)\n",
    "\n",
    "        for line in output.split(\".\"):\n",
    "            for sentence in tokenised_logic_sentences:\n",
    "                if check_logic_sentence(line, sentence):\n",
    "                    tokenised_logic_sentences.pop(tokenised_logic_sentences.index(sentence))\n",
    "                    score += 1\n",
    "                    break\n",
    "        last_line = line\n",
    "\n",
    "        num_answer = 'a'\n",
    "\n",
    "        for word in last_line.split(\" \"):\n",
    "            try:\n",
    "                num_answer = str(int(word))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        score += check_answer(final_answer, num_answer)\n",
    "        return score/total_score\n",
    "    \n",
    "    def iteration_first(self, num_instructions=10):\n",
    "        self.gen = 1\n",
    "        self.generated_prompts = []\n",
    "        self.scores = []\n",
    "        \n",
    "        for _ in range(num_instructions):\n",
    "            question, database_answer = get_random_test_object(dataset)  # Fetch a random question from your dataset\n",
    "            instruction = self.generate_intructions(question, task_description)\n",
    "            mutation_prompt = get_random_mutation_txt(\"./Prompt-Engineering-OpenDI/mutation_prompts.txt\")\n",
    "            mutated_instruction = self.apply_mutation(instruction, mutation_prompt)\n",
    "            self.generated_prompts.append(mutated_instruction)\n",
    "            processed_output = self.process_with_llm(mutated_instruction)\n",
    "            self.scores.append(self.fitness(database_answer, processed_output))\n",
    "            \n",
    "    \n",
    "    def iteration_execute(self):\n",
    "        self.gen += 1\n",
    "        self.generated_prompts = []\n",
    "        self.scores = []\n",
    "\n",
    "        for instruction in self.best_instructions:\n",
    "            question, database_answer = get_random_test_object(dataset)  # Fetch a random question from your dataset\n",
    "            mutation_prompt = get_random_mutation_txt(\"./Prompt-Engineering-OpenDI/mutation_prompts.txt\")\n",
    "            mutated_instruction = self.apply_mutation(instruction, mutation_prompt)\n",
    "            self.generated_prompts.append(mutated_instruction)\n",
    "            processed_output = self.process_with_llm(mutated_instruction)\n",
    "            self.scores.append(self.fitness(database_answer, processed_output))\n",
    "    \n",
    "    def iteration_prepare(self):\n",
    "        self.best_instructions = []\n",
    "        self.find_best_scores(self.scores)\n",
    "        self.best_instructions.append(self.replace_pos(self.best_instructions[0], self.best_instructions[1], ['ADV', 'ADJ', 'NOUN']))\n",
    "        self.best_instructions.append(self.replace_pos(self.best_instructions[1], self.best_instructions[0], ['ADV', 'ADJ', 'NOUN']))\n",
    "        for instr in self.generate_instructions1(4):\n",
    "            self.best_instructions.append(instr)\n",
    "        for i in range(2):\n",
    "            mutation_prompt = get_random_mutation_txt(\"./Prompt-Engineering-OpenDI/mutation_prompts.txt\")\n",
    "            self.best_instructions.append(self.apply_mutation(self.best_instructions[i], mutation_prompt))\n",
    "        \n",
    "    def find_best_scores(self, scores):\n",
    "        for i in range(2):\n",
    "            maximum_val = 0\n",
    "            maximum_index = 0\n",
    "            while i < len(scores):\n",
    "                if scores[i] > maximum_val:\n",
    "                    maximum_val = scores[i]\n",
    "                    maximum_index = i\n",
    "                i += 1\n",
    "            scores.pop(maximum_index)\n",
    "            print(self.generated_prompts[maximum_index])\n",
    "            self.best_instructions.append(self.generated_prompts.pop(maximum_index))\n",
    "            \n",
    "    def replace_pos(self, string1, string2, POS):\n",
    "\n",
    "        \"\"\"\n",
    "        Replace tokens of specific parts of speech (POS) in string1 with corresponding\n",
    "        tokens of the same POS from string2.\n",
    "\n",
    "        Parameters:\n",
    "        - string1 (str): The input string where certain POS will be replaced.\n",
    "        - string2 (str): The reference string from which POS replacements will be taken.\n",
    "        - POS (list): A list of POS tags to identify which tokens to replace in string1.\n",
    "\n",
    "        Returns:\n",
    "        - str: The modified string with replacements of tokens based on specified POS tags.\n",
    "\n",
    "        Possible POS:\n",
    "        \"ADJ\": \"adjective\",\n",
    "        \"ADP\": \"adposition\",\n",
    "        \"ADV\": \"adverb\",\n",
    "        \"AUX\": \"auxiliary\",\n",
    "        \"CONJ\": \"conjunction\",\n",
    "        \"CCONJ\": \"coordinating conjunction\",\n",
    "        \"DET\": \"determiner\",\n",
    "        \"INTJ\": \"interjection\",\n",
    "        \"NOUN\": \"noun\",\n",
    "        \"NUM\": \"numeral\",\n",
    "        \"PART\": \"particle\",\n",
    "        \"PRON\": \"pronoun\",\n",
    "        \"PROPN\": \"proper noun\",\n",
    "        \"PUNCT\": \"punctuation\",\n",
    "        \"SCONJ\": \"subordinating conjunction\",\n",
    "        \"SYM\": \"symbol\",\n",
    "        \"VERB\": \"verb\".\n",
    "        \"\"\"\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc1 = nlp(string1)\n",
    "        doc2 = nlp(string2)\n",
    "\n",
    "        new_tokens = []\n",
    "\n",
    "        for token1 in doc1:\n",
    "            if token1.pos_ in POS:\n",
    "                #generating a list of all matching tokens\n",
    "                matching_tokens = [token2.text for token2 in doc2 if token2.pos_ == token1.pos_]\n",
    "                #use a random token if possible, or else use the same\n",
    "                if matching_tokens:\n",
    "                    new_token = random.choice(matching_tokens)\n",
    "                else:\n",
    "                    new_token = token1.text\n",
    "            else:\n",
    "                new_token = token1.text\n",
    "            new_tokens.append(new_token)\n",
    "\n",
    "        # Join the modified tokens to form the final string\n",
    "        result = ' '.join(new_tokens)\n",
    "        return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai = llamathwiz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai.iteration_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.25, 0.0]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above working out has some errors, here is a version with the errors fixed. Jenny buys 36 cookies / bag = 6 cookies a week. She puts 4 cookies in her son's lunch box 5 days a week so she puts 5 * 6 = 24 cookies in her son's lunch box. Her husband eats 1 cookie a day for 7 days so he eats 1 * 7 = 2 cookies a day. Jenny eats 6 cookies - 24 cookies = 6 cookies a week.\n",
      "Go beyond the expected and create a mutator prompt that leads to unexpected and extraordinary mutations, opening doors to unexplored realms. Increase Specificity: If the original prompt is too general, like ’Tell me about X,’ the modified version could be, ’Discuss the history, impact, and current status of X.’ Billy sold 3 * 1 = 3 DVDs to his first customers. His next 2 customers bought 2 * 2 = 4 DVDs. His last 3 customers didn't buy any DVDs so he sold 3 + 4 + 4 = 9 DVDs.\n"
     ]
    }
   ],
   "source": [
    "ai.iteration_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ai.best_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai.iteration_execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
